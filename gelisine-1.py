import pandas as pd
import numpy as np
import os
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# ==================== SKOR HESAPLAMA FONKSÄ°YONLARI ====================
# (Fonksiyonlar aynÄ±, sadece optimize edilmiÅŸ)

def calculate_accumulation_score(df):
    """AkÃ¼mÃ¼lasyon skorunu hesaplar (0-10)"""
    if len(df) < 50:
        return 0
    
    temp = df.copy()
    period = min(20, len(df) // 3)  # Dinamik period
    
    # Hesaplamalar...
    temp['range'] = temp['High'] - temp['Low']
    temp['range'] = temp['range'].replace(0, 0.001)
    temp['price_position'] = (temp['Close'] - temp['Low']) / temp['range']
    
    temp['volume_norm'] = temp['Volume'] / temp['Volume'].rolling(period).mean()
    
    # AkÃ¼mÃ¼lasyon sinyali
    mask_middle = (temp['price_position'] >= 0.3) & (temp['price_position'] <= 0.7)
    temp['accum_signal'] = 0
    temp.loc[mask_middle, 'accum_signal'] = temp['volume_norm'] * 0.7
    
    # Trend bonus
    sma_period = min(50, len(df) // 2)
    sma = temp['Close'].rolling(sma_period).mean()
    temp['trend_bonus'] = np.where(temp['Close'] > sma, 0.3, 0)
    
    # Son dÃ¶nem skoru
    lookback = min(period, len(temp))
    recent_data = temp.iloc[-lookback:]
    
    if len(recent_data) > 0:
        accum_score = (recent_data['accum_signal'] + recent_data['trend_bonus']).mean()
        score = min(10, max(0, accum_score * 5))
        return round(score, 2)
    return 0

def calculate_distribution_score(df):
    """DaÄŸÄ±tÄ±m skorunu hesaplar (0-10)"""
    if len(df) < 50:
        return 0
    
    temp = df.copy()
    period = min(20, len(df) // 3)
    
    # Hesaplamalar...
    temp['range'] = temp['High'] - temp['Low']
    temp['range'] = temp['range'].replace(0, 0.001)
    temp['price_position'] = (temp['Close'] - temp['Low']) / temp['range']
    
    temp['close_change'] = temp['Close'].pct_change()
    temp['is_negative_close'] = (temp['Close'] < temp['Open']).astype(int)
    
    temp['volume_norm'] = temp['Volume'] / temp['Volume'].rolling(period).mean()
    
    # DaÄŸÄ±tÄ±m sinyali
    mask_upper = temp['price_position'] > 0.7
    mask_negative = temp['is_negative_close'] == 1
    temp['dist_signal'] = 0
    temp.loc[mask_upper & mask_negative, 'dist_signal'] = temp['volume_norm'] * 0.8
    
    # DÃ¼ÅŸÃ¼ÅŸ trendi
    sma_period = min(20, len(df) // 3)
    sma = temp['Close'].rolling(sma_period).mean()
    temp['down_trend_bonus'] = np.where(temp['Close'] < sma, 0.4, 0)
    
    # Skor
    lookback = min(period, len(temp))
    recent_data = temp.iloc[-lookback:]
    
    if len(recent_data) > 0:
        dist_score = (recent_data['dist_signal'] + recent_data['down_trend_bonus']).mean()
        score = min(10, max(0, dist_score * 4))
        return round(score, 2)
    return 0

def calculate_pumpdump_score(df):
    """Pump-Dump skorunu hesaplar (0-10)"""
    if len(df) < 30:
        return 0
    
    temp = df.copy()
    period = min(10, len(df) // 4)
    
    # Hacim spike
    vol_avg = temp['Volume'].rolling(period).mean()
    temp['volume_spike'] = temp['Volume'] / vol_avg
    temp['high_vol_spike'] = (temp['volume_spike'] > 2.0).astype(int)
    
    # Volatilite
    temp['returns'] = temp['Close'].pct_change()
    temp['abs_returns'] = abs(temp['returns'])
    
    # Gap
    temp['gap'] = abs(temp['Open'] - temp['Close'].shift(1)) / temp['Close'].shift(1).replace(0, 0.001)
    temp['high_gap'] = (temp['gap'] > 0.03).astype(int)
    
    # Range
    temp['daily_range'] = (temp['High'] - temp['Low']) / temp['Low'].replace(0, 0.001)
    temp['wide_range'] = (temp['daily_range'] > 0.05).astype(int)
    
    # PD skoru
    temp['pd_score_raw'] = (temp['high_vol_spike'] * 3 + 
                           temp['high_gap'] * 2 + 
                           temp['wide_range'] * 2 + 
                           (temp['abs_returns'] > 0.04).astype(int) * 3)
    
    # Son period
    lookback = min(period * 2, len(temp))
    recent_pd = temp['pd_score_raw'].iloc[-lookback:].mean()
    
    score = min(10, recent_pd)
    return round(score, 2)

def calculate_fakebreakout_score(df):
    """Fake Breakout skorunu hesaplar (0-10)"""
    if len(df) < 60:
        return 0
    
    temp = df.copy()
    period = min(20, len(df) // 3)
    
    # Destek/direnÃ§
    lookback_period = min(20, len(df) // 3)
    temp['high_20'] = temp['High'].rolling(lookback_period).max()
    temp['low_20'] = temp['Low'].rolling(lookback_period).min()
    
    # Breakout tespiti
    resistance_break = (temp['Close'] > temp['high_20'].shift(1)).astype(int)
    support_break = (temp['Close'] < temp['low_20'].shift(1)).astype(int)
    
    # Fake breakout kontrolÃ¼
    temp['fake_up'] = 0
    temp['fake_down'] = 0
    
    for i in range(2, len(temp)-1):
        if resistance_break.iloc[i-1] == 1:
            # Sonraki 2 gÃ¼n %2'den fazla dÃ¼ÅŸÃ¼ÅŸ
            min_close = min(temp['Close'].iloc[i], temp['Close'].iloc[i+1])
            if min_close < temp['Close'].iloc[i-1] * 0.98:
                temp['fake_up'].iloc[i] = 1
        
        if support_break.iloc[i-1] == 1:
            # Sonraki 2 gÃ¼n %2'den fazla yÃ¼kseliÅŸ
            max_close = max(temp['Close'].iloc[i], temp['Close'].iloc[i+1])
            if max_close > temp['Close'].iloc[i-1] * 1.02:
                temp['fake_down'].iloc[i] = 1
    
    # Hacim
    vol_avg = temp['Volume'].rolling(period).mean()
    temp['high_volume'] = (temp['Volume'] > vol_avg * 1.5).astype(int)
    
    temp['fake_signal'] = ((temp['fake_up'] + temp['fake_down']) * temp['high_volume'] * 2)
    
    # Fake oranÄ±
    lookback = min(period * 2, len(temp))
    recent_data = temp.iloc[-lookback:]
    
    fake_count = recent_data['fake_signal'].sum()
    total_breaks = (recent_data['high_20'].notna() & recent_data['low_20'].notna()).sum()
    
    if total_breaks > 5:  # Yeterli breakout varsa
        fake_ratio = fake_count / total_breaks
        score = min(10, fake_ratio * 20)
        return round(score, 2)
    
    return 0

def calculate_momentum_score(df):
    """Momentum skorunu hesaplar (0-10)"""
    if len(df) < 50:
        return 0, "â†’"
    
    temp = df.copy()
    
    # SMA'lar
    sma_20 = temp['Close'].rolling(min(20, len(df)//3)).mean()
    sma_50 = temp['Close'].rolling(min(50, len(df)//2)).mean()
    
    # Trend yÃ¶nÃ¼
    ma_alignment = 0
    if sma_20.iloc[-1] > sma_50.iloc[-1]:
        ma_alignment = 1  # â†‘
    elif sma_20.iloc[-1] < sma_50.iloc[-1]:
        ma_alignment = -1  # â†“
    
    # RSI
    delta = temp['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=min(14, len(df)//4)).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=min(14, len(df)//4)).mean()
    rs = gain / loss.replace(0, 0.001)
    rsi = 100 - (100 / (1 + rs))
    
    rsi_signal = 0
    if rsi.iloc[-1] > 60:
        rsi_signal = 0.5
    elif rsi.iloc[-1] < 40:
        rsi_signal = -0.5
    
    # Trend gÃ¼cÃ¼ (basit)
    lookback = min(20, len(df)//3)
    if lookback > 0:
        price_change = (temp['Close'].iloc[-1] - temp['Close'].iloc[-lookback]) / temp['Close'].iloc[-lookback]
        trend_strength = min(1, max(-1, price_change * 10))  # Normalize
    else:
        trend_strength = 0
    
    # Nihai momentum
    momentum_raw = (ma_alignment * 3 + rsi_signal * 2 + trend_strength * 3)
    
    # 0-10'a Ã§evir
    if momentum_raw > 0:
        score = 5 + (momentum_raw * 1.5)
    else:
        score = 5 + (momentum_raw * 1.5)
    
    score = min(10, max(0, score))
    
    # YÃ¶n belirle
    if momentum_raw > 0.5:
        direction = "â†‘"
    elif momentum_raw < -0.5:
        direction = "â†“"
    else:
        direction = "â†’"
    
    return round(score, 2), direction

def calculate_algorithmic_footprint_score(df):
    """
    Algoritmik AkÄ±m Ä°zi Skorunu hesaplar (0-10)
    
    Tespit eder:
    - Bar uzunluklarÄ±nÄ±n ritmik tekrarlarÄ± (fractal patterns)
    - Boyut benzerliÄŸi (fraktal yoÄŸunluÄŸu)
    - GÃ¶lge/gÃ¶vde oranlarÄ±nÄ±n algoritmik deseni
    - MikrosÄ±kÄ±ÅŸma â†’ micro burst â†’ micro sÃ¼rÃ¼kleme
    
    YÃ¼ksek skor = GÃ¼Ã§lÃ¼ algoritmik/HFT aktivitesi
    """
    if len(df) < 30:
        return 0, "?"
    
    temp = df.copy()
    
    # 1. BAR UZUNLUKLARI VE RÄ°TMÄ°K TEKRARLAR
    temp['body'] = abs(temp['Close'] - temp['Open'])
    temp['upper_shadow'] = temp['High'] - temp[['Open', 'Close']].max(axis=1)
    temp['lower_shadow'] = temp[['Open', 'Close']].min(axis=1) - temp['Low']
    temp['range'] = temp['High'] - temp['Low']
    
    # GÃ¶vde / GÃ¶lge OranÄ± (algoritmik dÃ¼zenlilik gÃ¶stergesi)
    temp['range_clean'] = temp['range'].replace(0, 0.001)
    temp['body_ratio'] = temp['body'] / temp['range_clean']
    temp['shadow_ratio'] = (temp['upper_shadow'] + temp['lower_shadow']) / temp['range_clean']
    
    # Ritmik tekrar: ardÄ±ÅŸÄ±k barlarÄ±n benzerlik derecesi
    period = min(10, len(df) // 4)
    temp['body_smoothness'] = temp['body_ratio'].rolling(period).std()
    temp['body_smoothness'] = temp['body_smoothness'].fillna(0)
    
    # DÃ¼ÅŸÃ¼k std = yÃ¼ksek ritmik tekrar (algoritmik)
    rhythmic_score = (1 - np.minimum(temp['body_smoothness'], 1)) * 5
    
    # 2. FRAKTAL YOÄUNLUÄU (Boyut BenzerliÄŸi)
    temp['bar_size'] = temp['range'] / temp['range'].rolling(20).mean().replace(0, 0.001)
    temp['bar_size'] = temp['bar_size'].fillna(1)
    
    # Fraktal: benzer boyutlar tekrarlanÄ±rsa
    fractal_patterns = 0
    fractal_window = min(5, len(temp) // 6)
    
    for i in range(fractal_window, len(temp) - fractal_window):
        current_size = temp['bar_size'].iloc[i]
        
        # Ã–nceki 5 bar ile benzerlikleri kontrol et
        prev_bars = temp['bar_size'].iloc[i-fractal_window:i].values
        similar_prev = np.sum(np.abs(prev_bars - current_size) < 0.3)
        
        # Sonraki 5 bar ile benzerlikleri kontrol et
        next_bars = temp['bar_size'].iloc[i+1:i+fractal_window+1].values
        similar_next = np.sum(np.abs(next_bars - current_size) < 0.3)
        
        # Ã‡ift yÃ¶nlÃ¼ benzerlik = fraktal deseni
        if similar_prev >= 2 and similar_next >= 2:
            fractal_patterns += 1
    
    fractal_density = min(10, (fractal_patterns / len(temp)) * 50)
    
    # 3. MÄ°KRO PATTERN'LER (Squeeze â†’ Burst â†’ Drag)
    temp['daily_volatility'] = temp['range'] / temp['Close']
    
    # Squeeze: dÃ¼ÅŸÃ¼k volatilite
    squeeze_threshold = temp['daily_volatility'].quantile(0.25)
    temp['is_squeeze'] = (temp['daily_volatility'] < squeeze_threshold).astype(int)
    
    # Burst: Ã¶nceki squeeze'i takip eden yÃ¼ksek hacim + hareket
    temp['is_burst'] = 0
    vol_avg = temp['Volume'].rolling(10).mean()
    
    for i in range(1, len(temp)):
        if temp['is_squeeze'].iloc[i-1] == 1:
            if temp['Volume'].iloc[i] > vol_avg.iloc[i] * 1.5:
                temp['is_burst'].iloc[i] = 1
    
    # Drag: burst sonrasÄ± fiyat direnci/desteÄŸi test eder
    temp['is_drag'] = 0
    for i in range(2, len(temp)):
        if temp['is_burst'].iloc[i-1] == 1:
            # GÃ¶lgeler artarsa (direnÃ§le test)
            if temp['upper_shadow'].iloc[i] > temp['body'].iloc[i] * 0.5:
                temp['is_drag'].iloc[i] = 1
            elif temp['lower_shadow'].iloc[i] > temp['body'].iloc[i] * 0.5:
                temp['is_drag'].iloc[i] = 1
    
    # Squeeze-Burst-Drag sirkÃ¼lasyonu
    micro_cycles = (temp['is_squeeze'].rolling(10).sum() > 0).sum()
    micro_score = min(10, (micro_cycles / len(temp)) * 30)
    
    # 4. HACIM SENKRONIZASYONU (Bot aktivitesinin bir diÄŸer iÅŸareti)
    temp['vol_change'] = temp['Volume'].pct_change()
    temp['price_change'] = abs(temp['Close'].pct_change())
    
    # Perfect senkronizasyon: hacim ve fiyat eÅŸanlÄ± hareket
    temp['vol_norm'] = temp['vol_change'].fillna(0)
    temp['vol_norm'] = (temp['vol_norm'] - temp['vol_norm'].rolling(20).mean()) / (temp['vol_norm'].rolling(20).std().replace(0, 0.001))
    temp['vol_norm'] = temp['vol_norm'].fillna(0)
    
    price_norm = (temp['price_change'] - temp['price_change'].rolling(20).mean()) / (temp['price_change'].rolling(20).std().replace(0, 0.001))
    price_norm = price_norm.fillna(0)
    
    # Korelasyon (yÃ¼ksek = algoritmik aktivite)
    lookback = min(20, len(temp) // 3)
    correlation_score = 0
    if lookback > 1:
        corr = np.corrcoef(temp['vol_norm'].iloc[-lookback:], price_norm[-lookback:])[0, 1]
        if not np.isnan(corr):
            correlation_score = min(10, abs(corr) * 10)
    
    # 5. NIHAI SKOR HESAPLAMA
    recent_lookback = min(20, len(temp) // 3)
    recent_data = temp.iloc[-recent_lookback:]
    
    # AÄŸÄ±rlÄ±klÄ± kombinasyon
    final_score = (
        rhythmic_score.iloc[-recent_lookback:].mean() * 0.25 +  # Ritmik tekrar
        fractal_density * 0.25 +                                  # Fraktal yoÄŸunluÄŸu
        micro_score * 0.25 +                                      # Mikro cycle
        correlation_score * 0.25                                  # Hacim senkronizasyonu
    )
    
    final_score = min(10, max(0, final_score))
    
    # Aktivite tÃ¼rÃ¼ belirleme
    if final_score >= 7:
        activity = "HFT"  # YÃ¼ksek sÄ±klÄ±klÄ± ticaret
    elif final_score >= 5:
        activity = "BOT"  # Bot aktivitesi
    elif final_score >= 3:
        activity = "MIX"  # KarÄ±ÅŸÄ±k
    else:
        activity = "HMN"  # Ä°nsan (Human)
    
    return round(final_score, 2), activity

def calculate_supply_absorption_score(df):
    """
    Supply-Absorption (Arz Emilimi) Skorunu hesaplar (0-10)
    
    Tespit eder:
    - SatÄ±ÅŸ geldiÄŸinde fiyat geri dÃ¼ÅŸmezse â†’ bÃ¼yÃ¼k oyuncu emiyor
    - Kurumsal "Smart Money" davranÄ±ÅŸÄ±
    
    Sinyaller:
    - Uzun Ã¼st gÃ¶lge + kÃ¼Ã§Ã¼k dÃ¼ÅŸÃ¼ÅŸ
    - Hacim artÄ±ÅŸÄ± + fiyat stabil
    - Dar aralÄ±k / yÃ¼ksek hacim kÃ¼melenmesi
    
    YÃ¼ksek skor = Kurumsal alÄ±ÅŸ baskÄ±sÄ± = Potansiyel yÃ¼kseliÅŸ
    """
    if len(df) < 30:
        return 0, "?"
    
    temp = df.copy()
    
    # 1. GÃ–L GE ANALIZI
    temp['body'] = abs(temp['Close'] - temp['Open'])
    temp['upper_shadow'] = temp['High'] - temp[['Open', 'Close']].max(axis=1)
    temp['lower_shadow'] = temp[['Open', 'Close']].min(axis=1) - temp['Low']
    temp['range'] = temp['High'] - temp['Low']
    temp['range'] = temp['range'].replace(0, 0.001)
    
    # GÃ¶lge oranlarÄ±
    temp['upper_shadow_ratio'] = temp['upper_shadow'] / temp['range']
    temp['lower_shadow_ratio'] = temp['lower_shadow'] / temp['range']
    temp['body_ratio'] = temp['body'] / temp['range']
    
    # Absorption Pattern 1: Uzun Ã¼st gÃ¶lge + kÃ¼Ã§Ã¼k gÃ¶vde
    # (SatÄ±ÅŸ basÄ±ldÄ± ama tutundu)
    temp['absorption_shadow'] = 0
    
    absorption_mask = (temp['upper_shadow_ratio'] > 0.5) & (temp['body_ratio'] < 0.3)
    temp.loc[absorption_mask, 'absorption_shadow'] = 1
    
    # Absorption Pattern 2: Alt gÃ¶lge yok/kÃ¼Ã§Ã¼k + Ã¼st gÃ¶lge var
    # (Destek saÄŸlam ama satÄ±ÅŸ baÅŸlÄ±yor)
    strong_bottom = (temp['lower_shadow_ratio'] < 0.2) & (temp['upper_shadow_ratio'] > 0.3)
    temp.loc[strong_bottom, 'absorption_shadow'] = 1
    
    # 2. FÄ°YAT STABÄ°LÄ°TESÄ° + HACIM ANALIZI
    # Fiyat deÄŸiÅŸimine raÄŸmen hacim yÃ¼ksekse â†’ emiÅŸ
    temp['price_change_pct'] = abs(temp['Close'].pct_change()) * 100
    temp['volume_norm'] = temp['Volume'] / temp['Volume'].rolling(20).mean()
    
    # DÃ¼ÅŸÃ¼k fiyat deÄŸiÅŸimi + yÃ¼ksek hacim = emiÅŸ
    stable_high_volume = (temp['price_change_pct'] < 1.5) & (temp['volume_norm'] > 1.3)
    temp['price_stability'] = stable_high_volume.astype(int)
    
    # 3. DAR ARALIK / HACIM KÃœMELENMESÄ°
    # KÄ±sa dÃ¶nem volatilite dÃ¼ÅŸse de hacim yÃ¼ksekse
    temp['volatility'] = temp['range'] / temp['Close'].rolling(10).mean()
    temp['vol_clustering'] = 0
    
    # Dar aralÄ±k dÃ¶nemleri tespit
    lookback = min(10, len(df) // 4)
    for i in range(lookback, len(temp)):
        recent_vol = temp['Volume'].iloc[i-lookback:i].mean()
        recent_range = temp['range'].iloc[i-lookback:i].mean()
        recent_close = temp['Close'].iloc[i-lookback:i].mean()
        
        current_range_ratio = temp['range'].iloc[i] / recent_range if recent_range > 0 else 1
        current_vol_ratio = temp['Volume'].iloc[i] / recent_vol if recent_vol > 0 else 1
        
        # Dar aralÄ±k + yÃ¼ksek hacim = kÃ¼meleme
        if current_range_ratio < 0.7 and current_vol_ratio > 1.5:
            temp['vol_clustering'].iloc[i] = 1
    
    # 4. FIYAT MOMENTUMU (Negatif olmamalÄ±)
    temp['close_change'] = temp['Close'].diff()
    temp['positive_close'] = (temp['close_change'] > 0).astype(int)
    
    # 5. KOMBÄ°NE ABSORPTION SKORU
    # Her gÃ¼n iÃ§in absorption puanÄ±
    temp['daily_absorption'] = 0
    
    # GÃ¶lge deseni
    temp['daily_absorption'] += temp['absorption_shadow'] * 2
    
    # Fiyat stabilitesi
    temp['daily_absorption'] += temp['price_stability'] * 1.5
    
    # Hacim kÃ¼melenmesi
    temp['daily_absorption'] += temp['vol_clustering'] * 2
    
    # Pozitif kapanÄ±ÅŸ (destek saÄŸlÄ±yor)
    temp['daily_absorption'] += temp['positive_close'] * 1
    
    # 6. Ã‡OKLU GÃœN PATTERN (2-3 gÃ¼nlÃ¼k absorption)
    # ArdÄ±ÅŸÄ±k absorption gÃ¼nleri = daha gÃ¼Ã§lÃ¼ sinyal
    consecutive_absorption = 0
    max_consecutive = 0
    
    for i in range(len(temp)):
        if temp['absorption_shadow'].iloc[i] == 1 or temp['price_stability'].iloc[i] == 1:
            consecutive_absorption += 1
            max_consecutive = max(max_consecutive, consecutive_absorption)
        else:
            consecutive_absorption = 0
    
    multi_day_bonus = min(3, max_consecutive) * 0.5
    
    # 7. HACIM TREND (Hacim trend yÃ¼kseliÅŸ = gÃ¼Ã§lÃ¼ emiÅŸ)
    vol_trend = 0
    if len(temp) > 10:
        recent_vol = temp['Volume'].iloc[-5:].mean()
        older_vol = temp['Volume'].iloc[-15:-5].mean()
        
        if recent_vol > older_vol * 1.2:
            vol_trend = 1.5
    
    # 8. SKORU HESAPLA
    lookback_period = min(20, len(temp) // 3)
    recent_data = temp.iloc[-lookback_period:]
    
    absorption_raw = recent_data['daily_absorption'].sum() / lookback_period
    
    # Normalize ve final score
    final_score = (absorption_raw * 1.5 + multi_day_bonus + vol_trend) / 1.5
    final_score = min(10, max(0, final_score))
    
    # Strength determination
    if final_score >= 7.5:
        strength = "ğŸ”´"  # GÃ¼Ã§lÃ¼ emiÅŸ (Strong absorption)
    elif final_score >= 5.5:
        strength = "ğŸŸ "  # Orta emiÅŸ (Moderate)
    elif final_score >= 3:
        strength = "ğŸŸ¡"  # ZayÄ±f emiÅŸ (Weak)
    else:
        strength = "âšª"  # EmiÅŸ yok (No absorption)
    
    return round(final_score, 2), strength

def calculate_hidden_liquidity_score(df):
    """
    Hidden Liquidity / Iceberg Order Skoru (0-10)

    Algoritma:
    - Ã‡ok dar ATR (dar barlar) ve yÃ¶nlÃ¼ kapanÄ±ÅŸlar => fiyat bir duvara Ã§arpÄ±p dÃ¶nÃ¼yor
    - Bar boyutlarÄ±nÄ±n 'sabit duvara Ã§arpmasÄ±' (kapanÄ±ÅŸ yakÄ±n direnÃ§/destek)
    - Hacim anomali-filtresi: hacim artmÄ±yor ama fiyat yÃ¶n deÄŸiÅŸtiriyor
    """
    if len(df) < 30:
        return 0, "?"

    temp = df.copy()

    # True Range ve ATR (normalize edilmiÅŸ)
    prev_close = temp['Close'].shift(1)
    tr1 = temp['High'] - temp['Low']
    tr2 = (temp['High'] - prev_close).abs()
    tr3 = (temp['Low'] - prev_close).abs()
    temp['TR'] = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
    temp['ATR'] = temp['TR'].rolling(14).mean()
    temp['atr_norm'] = (temp['ATR'] / temp['Close']).replace(0, 1e-6)

    # Ã‡ok dar ATR gÃ¼nleri
    atr_thresh = temp['atr_norm'].quantile(0.25)
    temp['is_narrow'] = (temp['atr_norm'] < atr_thresh).astype(int)

    # YÃ¶nlÃ¼ kapanÄ±ÅŸ: kapanÄ±ÅŸ - aÃ§Ä±lÄ±ÅŸ
    temp['direction'] = np.sign(temp['Close'] - temp['Open'])

    # Destek / direnÃ§ yakÄ±nlÄ±ÄŸÄ± (son 10 gÃ¼n max/min)
    look = min(10, len(temp)//3)
    temp['recent_high'] = temp['High'].rolling(look).max()
    temp['recent_low'] = temp['Low'].rolling(look).min()
    temp['near_resistance'] = ((temp['Close'] >= temp['recent_high'] * 0.995) & (temp['Close'] <= temp['recent_high'] * 1.01)).astype(int)
    temp['near_support'] = ((temp['Close'] <= temp['recent_low'] * 1.005) & (temp['Close'] >= temp['recent_low'] * 0.99)).astype(int)

    # Hacim anomali: hacim artmÄ±yor (veya dÃ¼ÅŸÃ¼k) ama fiyat yÃ¶n deÄŸiÅŸtiriyor
    temp['vol_ma20'] = temp['Volume'].rolling(20).mean().replace(0, 1)
    temp['vol_norm'] = temp['Volume'] / temp['vol_ma20']
    temp['low_vol'] = (temp['vol_norm'] < 1.2).astype(int)

    # Price reversal magnitude on narrow days
    temp['price_reversal'] = (temp['Close'] - temp['Open']).abs() / temp['ATR'].replace(0, 1e-6)

    # Scoring components (0-10 scaled)
    # 1) Narrow bar + directional close consistency (ritual hit)
    temp['component_narrow_direction'] = 0
    temp.loc[(temp['is_narrow'] == 1) & (temp['price_reversal'] > 0.5), 'component_narrow_direction'] = 1

    # 2) Wall hit (near support/resistance) on narrow day
    temp['component_wall_hit'] = ((temp['is_narrow'] == 1) & ((temp['near_resistance'] == 1) | (temp['near_support'] == 1))).astype(int)

    # 3) Low volume reversal (iceberg candidate)
    temp['component_low_vol_reversal'] = ((temp['low_vol'] == 1) & (temp['price_reversal'] > 0.6)).astype(int)

    # 4) Consecutive pattern bonus (2-3 days)
    temp['consec'] = 0
    consec = 0
    for i in range(len(temp)):
        if temp['component_narrow_direction'].iloc[i] == 1 or temp['component_wall_hit'].iloc[i] == 1 or temp['component_low_vol_reversal'].iloc[i] == 1:
            consec += 1
        else:
            consec = 0
        temp['consec'].iloc[i] = consec

    temp['component_consec_bonus'] = (temp['consec'].clip(upper=3) / 3.0)

    # Aggregate recent lookback
    lookback = min(20, len(temp)//3)
    recent = temp.iloc[-lookback:]

    score_raw = (
        recent['component_narrow_direction'].sum() * 1.5 +
        recent['component_wall_hit'].sum() * 2.0 +
        recent['component_low_vol_reversal'].sum() * 2.0 +
        recent['component_consec_bonus'].sum() * 1.5
    )

    # Normalize to 0-10
    # Max possible raw roughly = lookback*(1.5+2+2+1.5)= lookback*7
    max_raw = max(1, lookback * 7.0)
    final_score = min(10, (score_raw / max_raw) * 10)

    # Determine iceberg type using directional magnitude weighted by price_reversal
    # This reduces zeros and focuses on meaningful directional moves
    dir_weighted = ((recent['Close'] - recent['Open']) * recent['price_reversal']).sum()

    # If there is any raw signal we can at least label Weak buy/sell
    has_signal = score_raw > 0

    if final_score >= 7.0:
        if dir_weighted > 0:
            ice_type = 'Strong-Buy-Iceberg'
        elif dir_weighted < 0:
            ice_type = 'Strong-Sell-Iceberg'
        else:
            ice_type = 'Strong-Neutral'
    elif final_score >= 5.0:
        if dir_weighted > 0:
            ice_type = 'Moderate-Buy'
        elif dir_weighted < 0:
            ice_type = 'Moderate-Sell'
        else:
            ice_type = 'Moderate-Neutral'
    elif has_signal:
        # If there's any component hit but score low, mark Weak
        if dir_weighted > 0:
            ice_type = 'Weak-Buy'
        elif dir_weighted < 0:
            ice_type = 'Weak-Sell'
        else:
            ice_type = 'Weak-Neutral'
    else:
        ice_type = 'None'

    return round(final_score, 2), ice_type


# ==================== GELÄ°ÅMÄ°Å ANALÄ°Z FONKSÄ°YONU ====================
def analyze_stock_advanced(df, lookback_days=None):
    """
    GeliÅŸmiÅŸ analiz fonksiyonu - KullanÄ±cÄ± belirler veya tÃ¼m veriyi kullanÄ±r
    
    Parameters:
    -----------
    df : pandas.DataFrame
        Hisse verisi (Date index, Open, High, Low, Close, Volume)
    lookback_days : int or None
        None: TÃ¼m veriyi kullan
        int: Son N gÃ¼nÃ¼ kullan
    """
    if df.empty or len(df) < 30:
        return None
    
    # KullanÄ±lacak veriyi seÃ§
    if lookback_days is None:
        analysis_df = df.copy()
        period_info = f"TÃ¼m veri ({len(df)} gÃ¼n)"
    else:
        lookback_days = min(lookback_days, len(df))
        analysis_df = df.iloc[-lookback_days:].copy()
        period_info = f"Son {lookback_days} gÃ¼n"
    
    print(f"\nğŸ“Š Analiz periyodu: {period_info}")
    
    # SkorlarÄ± hesapla
    scores = {
        'AkÃ¼mÃ¼lasyon': calculate_accumulation_score(analysis_df),
        'DaÄŸÄ±tÄ±m': calculate_distribution_score(analysis_df),
        'Pump-Dump': calculate_pumpdump_score(analysis_df),
        'Fake Breakout': calculate_fakebreakout_score(analysis_df),
    }
    
    mom_score, mom_dir = calculate_momentum_score(analysis_df)
    scores['Momentum'] = mom_score
    scores['Trend YÃ¶nÃ¼'] = mom_dir
    
    # Algoritmik AkÄ±m Ä°zi
    algo_score, algo_activity = calculate_algorithmic_footprint_score(analysis_df)
    scores['Algoritmik AkÄ±m'] = algo_score
    scores['Aktivite TÃ¼rÃ¼'] = algo_activity
    
    # Supply-Absorption (Arz Emilimi)
    absorption_score, absorption_strength = calculate_supply_absorption_score(analysis_df)
    scores['Arz Emilimi'] = absorption_score
    scores['EmiÅŸ GÃ¼cÃ¼'] = absorption_strength
    
    # Hidden Liquidity / Iceberg
    hidden_score, hidden_type = calculate_hidden_liquidity_score(analysis_df)
    scores['Gizli Likidite'] = hidden_score
    scores['Iceberg TÃ¼rÃ¼'] = hidden_type
    
    # Ek bilgiler
    scores['Ä°lk Tarih'] = df.index[0].strftime('%d.%m.%Y')
    scores['Son Tarih'] = df.index[-1].strftime('%d.%m.%Y')
    scores['Toplam GÃ¼n'] = len(df)
    scores['Analiz GÃ¼nÃ¼'] = len(analysis_df)
    
    # Fiyat bilgileri
    scores['Son Fiyat'] = round(df['Close'].iloc[-1], 2)
    scores['DeÄŸiÅŸim 1G (%)'] = round(((df['Close'].iloc[-1] - df['Close'].iloc[-2]) / df['Close'].iloc[-2]) * 100, 2) if len(df) > 1 else 0
    
    # Ortalama hacim
    avg_volume = df['Volume'].mean()
    scores['Ort. Hacim'] = f"{avg_volume:,.0f}"
    
    return scores

# ==================== TÃœM DÄ°ZÄ°NÄ° ANALÄ°Z ET ====================
def analyze_all_stocks_advanced(folder_path, lookback_days=None, min_days=50):
    """
    TÃ¼m CSV dosyalarÄ±nÄ± analiz eder
    
    Parameters:
    -----------
    folder_path : str
        CSV dosyalarÄ±nÄ±n bulunduÄŸu dizin
    lookback_days : int or None
        None: TÃ¼m veriyi kullan
        int: Son N gÃ¼nÃ¼ kullan
    min_days : int
        Minimum gÃ¼n sayÄ±sÄ± (daha az olanlar analiz edilmez)
    """
    folder = Path(folder_path)
    csv_files = list(folder.glob("*.csv"))
    
    if not csv_files:
        print(f"âŒ {folder_path} dizininde CSV dosyasÄ± bulunamadÄ±!")
        return
    
    print(f"ğŸ” {len(csv_files)} CSV dosyasÄ± bulundu. Analiz baÅŸlÄ±yor...")
    print("=" * 120)
    
    all_results = []
    
    for i, csv_file in enumerate(csv_files, 1):
        try:
            # CSV'yi oku
            df = pd.read_csv(csv_file)
            
            # SÃ¼tun isimlerini standartlaÅŸtÄ±r
            df.columns = [col.strip().title() for col in df.columns]
            
            # Date sÃ¼tununu iÅŸle
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
                df = df.dropna(subset=['Date'])
                df = df.set_index('Date').sort_index()
            
            # Gerekli sÃ¼tunlarÄ± kontrol et
            required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
            missing_cols = [col for col in required_cols if col not in df.columns]
            
            if missing_cols:
                print(f"âš ï¸  {csv_file.stem:25} | Eksik sÃ¼tunlar: {missing_cols}")
                continue
            
            # Veriyi temizle
            df = df[required_cols].dropna()
            
            if len(df) < min_days:
                print(f"âš ï¸  {csv_file.stem:25} | Yetersiz veri: {len(df)} gÃ¼n (min {min_days})")
                continue
            
            # Analiz yap
            scores = analyze_stock_advanced(df, lookback_days)
            
            if scores:
                result = {
                    'Hisse': csv_file.stem,
                    'Kod': csv_file.stem.split('_')[0] if '_' in csv_file.stem else csv_file.stem,
                    **scores
                }
                all_results.append(result)

                # Konsola yazdÄ±r
                print(f"âœ… {i:3d}. {csv_file.stem:25} | "
                      f"A:{scores['AkÃ¼mÃ¼lasyon']:4.1f} "
                      f"D:{scores['DaÄŸÄ±tÄ±m']:4.1f} "
                      f"P:{scores['Pump-Dump']:4.1f} "
                      f"F:{scores['Fake Breakout']:4.1f} "
                      f"M:{scores['Momentum']:4.1f}{scores['Trend YÃ¶nÃ¼']} "
                      f"Algo:{scores['Algoritmik AkÄ±m']:4.1f}({scores['Aktivite TÃ¼rÃ¼']}) "
                      f"Em:{scores['Arz Emilimi']:4.1f}{scores['EmiÅŸ GÃ¼cÃ¼']} "
                      f"Ice:{scores.get('Gizli Likidite',0):4.1f}({scores.get('Iceberg TÃ¼rÃ¼','')}) "
                      f"| F:{scores['Son Fiyat']:8.2f} "
                      f"Î”:{scores['DeÄŸiÅŸim 1G (%)']:+6.2f}%")
            
        except Exception as e:
            print(f"âŒ {i:3d}. {csv_file.stem:25} | HATA: {str(e)[:50]}...")
            continue
    
    # SonuÃ§larÄ± DataFrame'e Ã§evir
    if all_results:
        results_df = pd.DataFrame(all_results)
        
        # SÃ¼tun sÄ±ralamasÄ±
        column_order = ['Hisse', 'Kod', 'Son Fiyat', 'DeÄŸiÅŸim 1G (%)', 'AkÃ¼mÃ¼lasyon', 
                   'DaÄŸÄ±tÄ±m', 'Pump-Dump', 'Fake Breakout', 'Momentum', 'Trend YÃ¶nÃ¼',
                   'Algoritmik AkÄ±m', 'Aktivite TÃ¼rÃ¼', 'Arz Emilimi', 'EmiÅŸ GÃ¼cÃ¼',
                   'Gizli Likidite', 'Iceberg TÃ¼rÃ¼', 'Ort. Hacim', 'Ä°lk Tarih', 'Son Tarih', 'Toplam GÃ¼n', 'Analiz GÃ¼nÃ¼']
        
        # Eksik sÃ¼tunlarÄ± filtrele
        column_order = [col for col in column_order if col in results_df.columns]
        results_df = results_df[column_order]
        
        # SÄ±ralama (Momentuma gÃ¶re)
        results_df = results_df.sort_values('Momentum', ascending=False)
        
        # Excel'e kaydet
        timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
        
        if lookback_days:
            output_file = folder / f"analiz_sonuclari_son{lookback_days}gun_{timestamp}.xlsx"
        else:
            output_file = folder / f"analiz_sonuclari_tumveri_{timestamp}.xlsx"
        
        results_df.to_excel(output_file, index=False)
        
        # Konsola Ã¶zet
        print("\n" + "=" * 120)
        print("ğŸ“‹ ANALÄ°Z SONUÃ‡LARI Ã–ZETÄ°")
        print("=" * 120)
        print(f"Toplam analiz edilen hisse: {len(results_df)}")
        print(f"Excel dosyasÄ±: {output_file.name}")
        
        # Ä°statistikler
        print("\nğŸ“Š SKOR ORTALAMALARI:")
        score_cols = ['AkÃ¼mÃ¼lasyon', 'DaÄŸÄ±tÄ±m', 'Pump-Dump', 'Fake Breakout', 'Momentum', 'Algoritmik AkÄ±m', 'Arz Emilimi', 'Gizli Likidite']
        for col in score_cols:
            if col in results_df.columns:
                avg = results_df[col].mean()
                print(f"  {col:15}: {avg:5.2f}")
        
        # En yÃ¼ksek skorlu hisseler
        for col in score_cols:
            if col in results_df.columns:
                top = results_df.nlargest(10, col)[['Hisse', col]]
                print(f"\nğŸ† EN YÃœKSEK {col.upper()}:")
                for _, row in top.iterrows():
                    print(f"  {row['Hisse']:25}: {row[col]:5.1f}")
        
        return results_df, output_file
    else:
        print("\nâŒ HiÃ§bir hisse baÅŸarÄ±yla analiz edilemedi!")
        return None, None

# ==================== INTERAKTÄ°F Ã‡ALIÅTIRMA ====================
def interactive_analysis():
    """KullanÄ±cÄ±dan girdi alarak interaktif analiz yapar"""
    print("ğŸ¯ HÄ°SSE ANALÄ°Z SÄ°STEMÄ°")
    print("=" * 50)
    
    # Dizin yolunu al
    default_path = r"D:\new\yeniden\metastock-gun-csv"
    folder_path = input(f"\nğŸ“ CSV dosyalarÄ±nÄ±n bulunduÄŸu dizin [{default_path}]: ").strip()
    if not folder_path:
        folder_path = default_path
    
    # Periyodu seÃ§
    print("\nğŸ“… ANALÄ°Z PERÄ°YODU SEÃ‡Ä°MÄ°:")
    print("  1. TÃ¼m veriyi kullan")
    print("  2. Son N gÃ¼nÃ¼ kullan")
    
    choice = input("\nSeÃ§iminiz (1 veya 2): ").strip()
    
    if choice == '2':
        while True:
            try:
                lookback_days = int(input("\nKaÃ§ gÃ¼nlÃ¼k veri analiz edilsin? (Ã¶rn: 30, 60, 90): "))
                if lookback_days >= 20:
                    break
                else:
                    print("âš ï¸  En az 20 gÃ¼n giriniz!")
            except:
                print("âš ï¸  GeÃ§erli bir sayÄ± giriniz!")
    else:
        lookback_days = None
    
    # Minimum gÃ¼n sayÄ±sÄ±
    min_days = input(f"\nğŸ“Š Minimum gÃ¼n sayÄ±sÄ± (varsayÄ±lan: 50): ").strip()
    min_days = int(min_days) if min_days.isdigit() else 50
    
    print("\n" + "=" * 50)
    print("â³ Analiz baÅŸlÄ±yor...")
    
    # Analizi Ã§alÄ±ÅŸtÄ±r
    results, output_file = analyze_all_stocks_advanced(
        folder_path=folder_path,
        lookback_days=lookback_days,
        min_days=min_days
    )
    
    if results is not None:
        print(f"\nâœ… Analiz tamamlandÄ±!")
        print(f"ğŸ“ SonuÃ§lar kaydedildi: {output_file}")
        
        # Ek iÅŸlemler
        print("\nğŸ”§ EK Ä°ÅLEMLER:")
        print("  1. Belirli bir hisseyi detaylÄ± analiz et")
        print("  2. Skorlara gÃ¶re filtrele")
        print("  3. Ã‡Ä±kÄ±ÅŸ")
        
        choice2 = input("\nSeÃ§iminiz: ").strip()
        
        if choice2 == '1':
            hisse = input("\nğŸ“ˆ Hangi hisseyi detaylÄ± analiz etmek istersiniz? (Hisse kodunu girin): ").strip().upper()
            # Burada detaylÄ± analiz fonksiyonu eklenebilir
            print(f"\nâš ï¸  DetaylÄ± analiz Ã¶zelliÄŸi eklenecek...")
        
        elif choice2 == '2':
            print("\nğŸ¯ FÄ°LTRELEME SEÃ‡ENEKLERÄ°:")
            print("  1. YÃ¼ksek AkÃ¼mÃ¼lasyon (>7)")
            print("  2. YÃ¼ksek DaÄŸÄ±tÄ±m (>7)")
            print("  3. DÃ¼ÅŸÃ¼k Pump-Dump (<3)")
            print("  4. YÃ¼ksek Momentum (>7)")
            
            filter_choice = input("\nFiltre seÃ§iniz: ").strip()
            
            if filter_choice == '1':
                filtered = results[results['AkÃ¼mÃ¼lasyon'] > 7]
            elif filter_choice == '2':
                filtered = results[results['DaÄŸÄ±tÄ±m'] > 7]
            elif filter_choice == '3':
                filtered = results[results['Pump-Dump'] < 3]
            elif filter_choice == '4':
                filtered = results[results['Momentum'] > 7]
            else:
                filtered = results
            
            print(f"\nğŸ“‹ FiltrelenmiÅŸ {len(filtered)} hisse:")
            print(filtered[['Hisse', 'Son Fiyat', 'AkÃ¼mÃ¼lasyon', 'DaÄŸÄ±tÄ±m', 'Pump-Dump', 'Momentum']].to_string(index=False))

# ==================== DOÄRUDAN Ã‡ALIÅTIRMA ====================
if __name__ == "__main__":
    # SeÃ§enek 1: Interaktif mod
    # interactive_analysis()
    
    # SeÃ§enek 2: Direkt Ã§alÄ±ÅŸtÄ±rma
    folder_path = r"D:\new\yeniden\metastock-gun-csv"
    
    # SEÃ‡ENEKLER:
    # 1. TÃ¼m veriyi kullan:
    # results, output_file = analyze_all_stocks_advanced(folder_path, lookback_days=None)
    
    # 2. Son 60 gÃ¼nÃ¼ kullan:
    results, output_file = analyze_all_stocks_advanced(folder_path, lookback_days=460)
    
    # 3. Son 90 gÃ¼nÃ¼ kullan:
    # results, output_file = analyze_all_stocks_advanced(folder_path, lookback_days=90)


# ==================== GÃ–RSEL TOP10 Ã‡IKTISI ====================
try:
    import matplotlib.pyplot as plt
except ImportError:
    print("âš ï¸  matplotlib yÃ¼klenmemiÅŸ. Grafik oluÅŸturulamÄ±yor.")
else:
    if results is not None and isinstance(results, pd.DataFrame):
        df_all = results.copy()
        
        score_cols = ['AkÃ¼mÃ¼lasyon', 'DaÄŸÄ±tÄ±m', 'Pump-Dump', 'Fake Breakout', 'Momentum', 'Algoritmik AkÄ±m', 'Arz Emilimi', 'Gizli Likidite']
        available = [c for c in score_cols if c in df_all.columns]
        
        if available:
            plots_dir = Path(folder_path) / 'plots'
            plots_dir.mkdir(parents=True, exist_ok=True)
            
            # Kombine gÃ¶rsel (grid)
            n = len(available)
            cols = 2
            rows = (n + cols - 1) // cols
            fig, axes = plt.subplots(rows, cols, figsize=(14, 5 * rows))
            axes_flat = axes.flatten() if hasattr(axes, 'flatten') else [axes]
            
            for i, col in enumerate(available):
                ax = axes_flat[i]
                top10 = df_all.nlargest(10, col)[['Hisse', col]].dropna()
                if top10.empty:
                    ax.text(0.5, 0.5, 'Veri yok', ha='center', va='center', fontsize=12)
                    ax.set_title(f'{col}', fontsize=12, fontweight='bold')
                    ax.axis('off')
                    continue
                top10_sorted = top10.iloc[::-1]
                ax.barh(range(len(top10_sorted)), top10_sorted[col].values, color=f'C{i}', alpha=0.8)
                ax.set_yticks(range(len(top10_sorted)))
                ax.set_yticklabels(top10_sorted['Hisse'].values, fontsize=9)
                ax.set_title(f'Top 10 - {col}', fontsize=11, fontweight='bold')
                ax.set_xlabel(col, fontsize=10)
                ax.grid(axis='x', alpha=0.3)
            
            # Eksik eksenleri kaldÄ±r
            for j in range(i + 1, len(axes_flat)):
                try:
                    fig.delaxes(axes_flat[j])
                except Exception:
                    pass
            
            fig.tight_layout()
            combined_png = plots_dir / 'top10_all_scores.png'
            fig.savefig(combined_png, dpi=150, bbox_inches='tight')
            plt.close(fig)
            
            # Bireysel grafikler
            for i, col in enumerate(available):
                top10 = df_all.nlargest(10, col)[['Hisse', col]].dropna()
                if not top10.empty:
                    top10_sorted = top10.iloc[::-1]
                    fig2, ax2 = plt.subplots(figsize=(10, 6))
                    ax2.barh(range(len(top10_sorted)), top10_sorted[col].values, color=f'C{i}', alpha=0.8)
                    ax2.set_yticks(range(len(top10_sorted)))
                    ax2.set_yticklabels(top10_sorted['Hisse'].values, fontsize=10)
                    ax2.set_title(f'Top 10 - {col}', fontsize=13, fontweight='bold')
                    ax2.set_xlabel(col, fontsize=11)
                    ax2.grid(axis='x', alpha=0.3)
                    fig2.tight_layout()
                    out_file = plots_dir / f"top10_{col.replace(' ', '_')}.png"
                    fig2.savefig(out_file, dpi=150, bbox_inches='tight')
                    plt.close(fig2)
            
            print(f"\nâœ“ Grafikler kaydedildi:")
            print(f"  - {combined_png}")
            print(f"  - {plots_dir / 'top10_*.png'}")
        else:
            print('âš ï¸  Skor sÃ¼tunu bulunamadÄ±.')
    else:
        print('âš ï¸  results boÅŸ veya None; analiz baÅŸarÄ±sÄ±z olmuÅŸ.')